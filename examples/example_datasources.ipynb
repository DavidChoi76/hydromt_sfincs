{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to show how to work with different dataset sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain rasterdata, we can use a HydroMT DataCatalog. There are several pre-defined DataCatalogs:\n",
    "<ul> \n",
    "<li><b><i>artifact_data </i></b>: Piave basin in Northern Italy (example data) </li>\n",
    "<li><b><i>deltares_data </i></b>: global datasets hosted on the p-drive</li>\n",
    "<li><b><i>opendap_data (in progress ...) </i></b>: global tiled datasets hosted on the opendap server</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydromt\n",
    "data_catalog = hydromt.DataCatalog(data_libs=[\"artifact_data\"])\n",
    "ds = data_catalog.get_rasterdataset(\"merit_hydro\")\n",
    "\n",
    "# merit hydro has multiple variables; select one\n",
    "ds[\"elevtn\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Often we don't need the entire extent of certain datasets, but only part of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each model can be initialized with a data_catalog\n",
    "# this works similar to the data_catalog above but now we use \n",
    "\n",
    "from hydromt_sfincs import SfincsModel\n",
    "# Initialize SfincsModel with the artifact data catalog which contains data for North Italy\n",
    "sf = SfincsModel(data_libs=[\"deltares_data\"], root=\"tmp_example\")\n",
    "inp_dict = {\n",
    "    \"x0\": 268650,\n",
    "    \"y0\": 5018550,\n",
    "    \"dx\": 200.0,\n",
    "    \"dy\": 200.0,\n",
    "    \"nmax\": 272,\n",
    "    \"mmax\": 425,\n",
    "    \"rotation\": 0,\n",
    "    \"epsg\": 32633,\n",
    "}\n",
    "# create grid\n",
    "sf.create_grid(grid_type=\"regular\", **inp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we already know where our model is, we minimize the amount of data that is read-in by specifying the region:\n",
    "\n",
    "da_dep1 = sf.data_catalog.get_rasterdataset(\n",
    "    \"merit_hydro\", variables=[\"elevtn\"], geom=sf.region, buffer=5\n",
    ")\n",
    "\n",
    "da_dep2 = sf.data_catalog.get_rasterdataset(\n",
    "    \"gebco\", variables=[\"elevtn\"], geom=sf.region, buffer=5\n",
    ")\n",
    "\n",
    "\n",
    "# to create dep or subgrid for SFINCS model, we need to specify the da_dep_lst which is a list of dictionaries with the dataset (da) and merge_arguments (e.g. zmax and offset)\n",
    "\n",
    "da_dep_lst = [{\"da\":da_dep1, \"min_valid\":0}, {\"da\":da_dep2, \"offset\":0} ]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermezzo: We can also download the data to a local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of data sources to export\n",
    "source_list = [\"fabdem\",\"gebco\"]\n",
    "# Geographic extent\n",
    "bbox = sf.region.to_crs(4326).total_bounds\n",
    "\n",
    "folder_name = \"tmp_data_export\"\n",
    "sf.data_catalog.export_data(\n",
    "    data_root=folder_name,\n",
    "    bbox=bbox,\n",
    "    source_names=source_list,\n",
    "    meta={\"version\": \"1\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local data can be added to the model as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the local geotiff you want to use:\n",
    "localtiff = \"c:\\\\github\\\\hydromt_sfincs\\\\examples\\\\tmp_data_export\\\\fabdem.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first option that exist is openning raster data with for example xarray:\n",
    "import xarray as xr\n",
    "ds_xarray = xr.open_dataset(localtiff)\n",
    "ds_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second and more elegant option is to use the data_catalog functionalities\n",
    "# This also adds the data to the data_catalog, so you can use it later on in your workflow without having to specify the path again\n",
    "# This also allows to keep track which data is actually used in your model (for reproducibility)\n",
    "# and it has additional options to get the data for partly using bbox, region, zoom_level etc.\n",
    "\n",
    "ds = sf.data_catalog.get_rasterdataset(\n",
    "    path_or_key=localtiff,\n",
    "    variables=['elevtn'],\n",
    "    geom=sf.region,\n",
    "    meta={\"version\": \"1\"},\n",
    "    )\n",
    "\n",
    "# added to data_catalog\n",
    "sf.data_catalog.sources\n",
    "# OR\n",
    "# sf.data_catalog[\"fabdem\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For higher-resolution datasets, sometimes making xyz-tiles is beneficial for speed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabdem = sf.data_catalog.get_rasterdataset(\"fabdem\")\n",
    "\n",
    "name = f\"fabdem_xyz\"\n",
    "root = os.path.join(folder_name, name)\n",
    "\n",
    "fabdem.raster.to_xyz_tiles(\n",
    "    root=root,\n",
    "    tile_size=256,\n",
    "    zoom_levels=[0,1,2,3],\n",
    "    driver=\"GTiff\",\n",
    "    compress=\"deflate\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabdem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now build a model that uses:\n",
    "<ul> \n",
    "<li><b><i>local dataset </i></b>: Local download of gebco </li>\n",
    "<li><b><i>data catalog xyz-tiles </i></b>: Local xyz tiles of fabdem</li>\n",
    "<li><b><i>delft dashboard data (in progress)</i></b>: global tiled datasets hosted on the opendap server</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = SfincsModel(data_libs=[\"artifact_data\",r\"c:\\github\\hydromt_sfincs\\examples\\tmp_data_export\\fabdem_xyz\\fabdem_xyz.yml\"], root=\"tmp_example\")\n",
    "inp_dict = {\n",
    "    \"x0\": 268650,\n",
    "    \"y0\": 5018550,\n",
    "    \"dx\": 200.0,\n",
    "    \"dy\": 200.0,\n",
    "    \"nmax\": 272,\n",
    "    \"mmax\": 425,\n",
    "    \"rotation\": 0,\n",
    "    \"epsg\": 32633,\n",
    "}\n",
    "# create grid\n",
    "sf.create_grid(grid_type=\"regular\", **inp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dep1 = sf.data_catalog.get_rasterdataset(\n",
    "    \"merit_hydro\", variables=[\"elevtn\"], geom=sf.region, buffer=5\n",
    ")\n",
    "\n",
    "da_dep2 = sf.data_catalog.get_rasterdataset(\n",
    "    r\"c:\\github\\hydromt_sfincs\\examples\\tmp_data_export\\gebco.tif\",\n",
    "    variables=[\"elevtn\"],\n",
    ")\n",
    "\n",
    "# Make sure that you also load your local data_catalog if you want to use it in your model\n",
    "# In this example, we only imported the fabdem_xyz.yml file, but this could be easily merged into one file to have a local data_catalog containing more datasets\n",
    "da_dep3 = sf.data_catalog.get_rasterdataset(\n",
    "    \"fabdem_xyz\",\n",
    "    variables=[\"elevtn\"], \n",
    "    zoom_level = (sf.config[\"dx\"], 'meter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the de_dep_lst. The order determines the priority of the datasets. Each dataset is a dictionary with the dataset (da) and merge_arguments\n",
    "da_dep_lst = [{\"da\":da_dep1, \"min_valid\":0.001},\n",
    "              {\"da\":da_dep2, \"offset\":0}, \n",
    "              {\"da\":da_dep3, \"min_valid\":0.001, \"merge_method\": \"last\"} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = sf.create_dep(da_dep_lst=da_dep_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.grid[\"dep\"].plot.imshow(vmin=-10, vmax=10, cmap=\"terrain\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydromt-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1c0d40e2688e13ef4c1e0a0bd8d32101069a8b3879fd20a3f04202f98b0ae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
